{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow script mode training and serving\n",
    "\n",
    "Script mode is a training script format for TensorFlow that lets you execute any TensorFlow training script in SageMaker with minimal modification. The [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) handles transferring your script to a SageMaker training instance. On the training instance, SageMaker's native TensorFlow support sets up training-related environment variables and executes your training script. In this tutorial, we use the SageMaker Python SDK to launch a training job and deploy the trained model.\n",
    "\n",
    "Script mode supports training with a Python script, a Python module, or a shell script. In this example, we use a Python script to train a classification model on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). In addition, this notebook demonstrates how to perform real time inference with the [SageMaker TensorFlow Serving container](https://github.com/aws/sagemaker-tensorflow-serving-container). The TensorFlow Serving container is the default inference method for script mode. For full documentation on the TensorFlow Serving container, please visit [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment\n",
    "\n",
    "Let's start by setting up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "The MNIST dataset has been loaded to the public S3 buckets ``sagemaker-sample-data-<REGION>`` under the prefix ``tensorflow/mnist``. There are four ``.npy`` file under this prefix:\n",
    "* ``train_data.npy``\n",
    "* ``eval_data.npy``\n",
    "* ``train_labels.npy``\n",
    "* ``eval_labels.npy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_uri = 's3://sagemaker-sample-data-{}/tensorflow/mnist'.format(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a script for distributed training\n",
    "\n",
    "This tutorial's training script was adapted from TensorFlow's official [CNN MNIST example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py). We have modified it to handle the ``model_dir`` parameter passed in by SageMaker. This is an S3 path which can be used for data sharing during distributed training and checkpointing and/or model persistence. We have also added an argument-parsing function to handle processing training-related variables.\n",
    "\n",
    "At the end of the training job we have added a step to export the trained model to the path stored in the environment variable ``SM_MODEL_DIR``, which always points to ``/opt/ml/model``. This is critical because SageMaker uploads all the model artifacts in this folder to S3 at end of training.\n",
    "\n",
    "Here is the entire script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2018-2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\r\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\r\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\r\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\r\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\r\n",
      "\u001b[37m# language governing permissions and limitations under the License.\u001b[39;49;00m\r\n",
      "\u001b[33m\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m absolute_import\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m division\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow.python.platform\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m tf_logging\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36m_logging\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36m_sys\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mcnn_model_fn\u001b[39;49;00m(features, labels, mode):\r\n",
      "    \u001b[33m\"\"\"Model function for CNN.\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[37m# Input Layer\u001b[39;49;00m\r\n",
      "    \u001b[37m# Reshape X to 4-D tensor: [batch_size, width, height, channels]\u001b[39;49;00m\r\n",
      "    \u001b[37m# MNIST images are 28x28 pixels, and have one color channel\u001b[39;49;00m\r\n",
      "    input_layer = tf.reshape(features[\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], [-\u001b[34m1\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[37m# Convolutional Layer #1\u001b[39;49;00m\r\n",
      "    \u001b[37m# Computes 32 features using a 5x5 filter with ReLU activation.\u001b[39;49;00m\r\n",
      "    \u001b[37m# Padding is added to preserve width and height.\u001b[39;49;00m\r\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 28, 28, 1]\u001b[39;49;00m\r\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 28, 28, 32]\u001b[39;49;00m\r\n",
      "    conv1 = tf.layers.conv2d(\r\n",
      "        inputs=input_layer,\r\n",
      "        filters=\u001b[34m32\u001b[39;49;00m,\r\n",
      "        kernel_size=[\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m],\r\n",
      "        padding=\u001b[33m\"\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        activation=tf.nn.relu)\r\n",
      "\r\n",
      "    \u001b[37m# Pooling Layer #1\u001b[39;49;00m\r\n",
      "    \u001b[37m# First max pooling layer with a 2x2 filter and stride of 2\u001b[39;49;00m\r\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 28, 28, 32]\u001b[39;49;00m\r\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 14, 14, 32]\u001b[39;49;00m\r\n",
      "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], strides=\u001b[34m2\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Convolutional Layer #2\u001b[39;49;00m\r\n",
      "    \u001b[37m# Computes 64 features using a 5x5 filter.\u001b[39;49;00m\r\n",
      "    \u001b[37m# Padding is added to preserve width and height.\u001b[39;49;00m\r\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 14, 14, 32]\u001b[39;49;00m\r\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 14, 14, 64]\u001b[39;49;00m\r\n",
      "    conv2 = tf.layers.conv2d(\r\n",
      "        inputs=pool1,\r\n",
      "        filters=\u001b[34m64\u001b[39;49;00m,\r\n",
      "        kernel_size=[\u001b[34m5\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m],\r\n",
      "        padding=\u001b[33m\"\u001b[39;49;00m\u001b[33msame\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\r\n",
      "        activation=tf.nn.relu)\r\n",
      "\r\n",
      "    \u001b[37m# Pooling Layer #2\u001b[39;49;00m\r\n",
      "    \u001b[37m# Second max pooling layer with a 2x2 filter and stride of 2\u001b[39;49;00m\r\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 14, 14, 64]\u001b[39;49;00m\r\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 7, 7, 64]\u001b[39;49;00m\r\n",
      "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[\u001b[34m2\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m], strides=\u001b[34m2\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Flatten tensor into a batch of vectors\u001b[39;49;00m\r\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 7, 7, 64]\u001b[39;49;00m\r\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 7 * 7 * 64]\u001b[39;49;00m\r\n",
      "    pool2_flat = tf.reshape(pool2, [-\u001b[34m1\u001b[39;49;00m, \u001b[34m7\u001b[39;49;00m * \u001b[34m7\u001b[39;49;00m * \u001b[34m64\u001b[39;49;00m])\r\n",
      "\r\n",
      "    \u001b[37m# Dense Layer\u001b[39;49;00m\r\n",
      "    \u001b[37m# Densely connected layer with 1024 neurons\u001b[39;49;00m\r\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 7 * 7 * 64]\u001b[39;49;00m\r\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 1024]\u001b[39;49;00m\r\n",
      "    dense = tf.layers.dense(inputs=pool2_flat, units=\u001b[34m1024\u001b[39;49;00m, activation=tf.nn.relu)\r\n",
      "\r\n",
      "    \u001b[37m# Add dropout operation; 0.6 probability that element will be kept\u001b[39;49;00m\r\n",
      "    dropout = tf.layers.dropout(\r\n",
      "        inputs=dense, rate=\u001b[34m0.4\u001b[39;49;00m, training=mode == tf.estimator.ModeKeys.TRAIN)\r\n",
      "\r\n",
      "    \u001b[37m# Logits layer\u001b[39;49;00m\r\n",
      "    \u001b[37m# Input Tensor Shape: [batch_size, 1024]\u001b[39;49;00m\r\n",
      "    \u001b[37m# Output Tensor Shape: [batch_size, 10]\u001b[39;49;00m\r\n",
      "    logits = tf.layers.dense(inputs=dropout, units=\u001b[34m10\u001b[39;49;00m)\r\n",
      "\r\n",
      "    predictions = {\r\n",
      "        \u001b[37m# Generate predictions (for PREDICT and EVAL mode)\u001b[39;49;00m\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mclasses\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.argmax(\u001b[36minput\u001b[39;49;00m=logits, axis=\u001b[34m1\u001b[39;49;00m),\r\n",
      "        \u001b[37m# Add `softmax_tensor` to the graph. It is used for PREDICT and by the\u001b[39;49;00m\r\n",
      "        \u001b[37m# `logging_hook`.\u001b[39;49;00m\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mprobabilities\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.nn.softmax(logits, name=\u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax_tensor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    }\r\n",
      "    \u001b[34mif\u001b[39;49;00m mode == tf.estimator.ModeKeys.PREDICT:\r\n",
      "      \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\r\n",
      "\r\n",
      "    \u001b[37m# Calculate Loss (for both TRAIN and EVAL modes)\u001b[39;49;00m\r\n",
      "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\r\n",
      "\r\n",
      "    \u001b[37m# Configure the Training Op (for TRAIN mode)\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "      optimizer = tf.train.GradientDescentOptimizer(learning_rate=\u001b[34m0.001\u001b[39;49;00m)\r\n",
      "      train_op = optimizer.minimize(\r\n",
      "          loss=loss,\r\n",
      "          global_step=tf.train.get_global_step())\r\n",
      "      \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n",
      "\r\n",
      "    \u001b[37m# Add evaluation metrics (for EVAL mode)\u001b[39;49;00m\r\n",
      "    eval_metric_ops = {\r\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: tf.metrics.accuracy(\r\n",
      "            labels=labels, predictions=predictions[\u001b[33m\"\u001b[39;49;00m\u001b[33mclasses\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])}\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.EstimatorSpec(\r\n",
      "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_training_data\u001b[39;49;00m(base_dir):\r\n",
      "    x_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    y_train = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_train, y_train\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_load_testing_data\u001b[39;49;00m(base_dir):\r\n",
      "    x_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_data.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    y_test = np.load(os.path.join(base_dir, \u001b[33m'\u001b[39;49;00m\u001b[33meval_labels.npy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m x_test, y_test\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_args\u001b[39;49;00m():\r\n",
      "\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    \u001b[37m# Data, model, and output directories\u001b[39;49;00m\r\n",
      "    \u001b[37m# model_dir is always passed in from SageMaker. By default this is a S3 path under the default bucket.\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_known_args()\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mserving_input_fn\u001b[39;49;00m():\r\n",
      "    inputs = {\u001b[33m'\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.placeholder(tf.float32, [\u001b[36mNone\u001b[39;49;00m, \u001b[34m784\u001b[39;49;00m])}\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m tf.estimator.export.ServingInputReceiver(inputs, inputs)\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "    args, unknown = _parse_args()\r\n",
      "\r\n",
      "    train_data, train_labels = _load_training_data(args.train)\r\n",
      "    eval_data, eval_labels = _load_testing_data(args.train)\r\n",
      "\r\n",
      "    \u001b[37m# Create the Estimator\u001b[39;49;00m\r\n",
      "    mnist_classifier = tf.estimator.Estimator(\r\n",
      "        model_fn=cnn_model_fn, model_dir=args.model_dir)\r\n",
      "\r\n",
      "    \u001b[37m# Set up logging for predictions\u001b[39;49;00m\r\n",
      "    \u001b[37m# Log the values in the \"Softmax\" tensor with label \"probabilities\"\u001b[39;49;00m\r\n",
      "    tensors_to_log = {\u001b[33m\"\u001b[39;49;00m\u001b[33mprobabilities\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: \u001b[33m\"\u001b[39;49;00m\u001b[33msoftmax_tensor\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m}\r\n",
      "    logging_hook = tf.train.LoggingTensorHook(\r\n",
      "        tensors=tensors_to_log, every_n_iter=\u001b[34m50\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Train the model\u001b[39;49;00m\r\n",
      "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n",
      "        x={\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: train_data},\r\n",
      "        y=train_labels,\r\n",
      "        batch_size=\u001b[34m100\u001b[39;49;00m,\r\n",
      "        num_epochs=\u001b[34m20\u001b[39;49;00m,\r\n",
      "        shuffle=\u001b[36mTrue\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# Evaluate the model and print results\u001b[39;49;00m\r\n",
      "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\r\n",
      "        x={\u001b[33m\"\u001b[39;49;00m\u001b[33mx\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: eval_data},\r\n",
      "        y=eval_labels,\r\n",
      "        num_epochs=\u001b[34m1\u001b[39;49;00m,\r\n",
      "        shuffle=\u001b[36mFalse\u001b[39;49;00m)\r\n",
      "\r\n",
      "    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=\u001b[34m20000\u001b[39;49;00m)\r\n",
      "    eval_spec = tf.estimator.EvalSpec(eval_input_fn)\r\n",
      "    tf.estimator.train_and_evaluate(mnist_classifier, train_spec, eval_spec)\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m args.current_host == args.hosts[\u001b[34m0\u001b[39;49;00m]:\r\n",
      "        mnist_classifier.export_savedmodel(args.sm_model_dir, serving_input_fn)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'mnist.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training job using the `TensorFlow` estimator\n",
    "\n",
    "The `sagemaker.tensorflow.TensorFlow` estimator handles locating the script mode container, uploading your script to a S3 location and creating a SageMaker training job. Let's call out a couple important parameters here:\n",
    "\n",
    "* `py_version` is set to `'py3'` to indicate that we are using script mode since legacy mode supports only Python 2. Though Python 2 will be deprecated soon, you can use script mode with Python 2 by setting `py_version` to `'py2'` and `script_mode` to `True`.\n",
    "\n",
    "* `distributions` is used to configure the distributed training setup. It's required only if you are doing distributed training either across a cluster of instances or across multiple GPUs. Here we are using parameter servers as the distributed training schema. SageMaker training jobs run on homogeneous clusters. To make parameter server more performant in the SageMaker setup, we run a parameter server on every instance in the cluster, so there is no need to specify the number of parameter servers to launch. Script mode also supports distributed training with [Horovod](https://github.com/horovod/horovod). You can find the full documentation on how to configure `distributions` [here](https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/tensorflow#distributed-training). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "mnist_estimator = TensorFlow(entry_point='mnist.py',\n",
    "                             role=role,\n",
    "                             train_instance_count=2,\n",
    "                             train_instance_type='ml.p3.2xlarge',\n",
    "                             framework_version='1.14',\n",
    "                             py_version='py3',\n",
    "                             distributions={'parameter_server': {'enabled': True}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling ``fit``\n",
    "\n",
    "To start a training job, we call `estimator.fit(training_data_uri)`.\n",
    "\n",
    "An S3 location is used here as the input. `fit` creates a default channel named `'training'`, which points to this S3 location. In the training script we can then access the training data from the location stored in `SM_CHANNEL_TRAINING`. `fit` accepts a couple other types of input as well. See the API doc [here](https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.EstimatorBase.fit) for details.\n",
    "\n",
    "When training starts, the TensorFlow container executes mnist.py, passing `hyperparameters` and `model_dir` from the estimator as script arguments. Because we didn't define either in this example, no hyperparameters are passed, and `model_dir` defaults to `s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>`, so the script execution is as follows:\n",
    "```bash\n",
    "python mnist.py --model_dir s3://<DEFAULT_BUCKET>/<TRAINING_JOB_NAME>\n",
    "```\n",
    "When training is complete, the training job will upload the saved model for TensorFlow serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-19 18:32:07 Starting - Starting the training job...\n",
      "2020-02-19 18:32:09 Starting - Launching requested ML instances......\n",
      "2020-02-19 18:33:14 Starting - Preparing the instances for training......\n",
      "2020-02-19 18:34:28 Downloading - Downloading input data...\n",
      "2020-02-19 18:34:56 Training - Downloading the training image...\n",
      "2020-02-19 18:35:25 Training - Training image download completed. Training in progress.\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[35mW0219 18:35:25.565686 139747622438656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0219 18:35:25.566142 139747622438656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW0219 18:35:29.224306 140531882161920 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:99: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0219 18:35:29.224795 140531882161920 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/site-packages/sagemaker_tensorflow_container/training.py:101: The name tf.train.Server is deprecated. Please use tf.distribute.Server instead.\n",
      "\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[35m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[35mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[35mW0219 18:35:31.360070 140369995765504 deprecation_wrapper.py:119] From mnist.py:161: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0219 18:35:31.360411 140369995765504 deprecation_wrapper.py:119] From mnist.py:165: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0219 18:35:31.360544 140369995765504 deprecation_wrapper.py:119] From mnist.py:165: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[34mWARNING: Logging before flag parsing goes to stderr.\u001b[0m\n",
      "\u001b[34mW0219 18:35:32.443654 140028400588544 deprecation_wrapper.py:119] From mnist.py:161: The name tf.train.LoggingTensorHook is deprecated. Please use tf.estimator.LoggingTensorHook instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0219 18:35:32.444042 140028400588544 deprecation_wrapper.py:119] From mnist.py:165: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0219 18:35:32.444187 140028400588544 deprecation_wrapper.py:119] From mnist.py:165: The name tf.estimator.inputs.numpy_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.numpy_input_fn instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0219 18:35:33.356517 140028400588544 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[34mW0219 18:35:33.429697 140028400588544 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mW0219 18:35:33.431277 140028400588544 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[34mW0219 18:35:33.442176 140028400588544 deprecation.py:323] From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[34mW0219 18:35:33.444895 140028400588544 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[34mW0219 18:35:33.688333 140028400588544 deprecation.py:323] From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[34mW0219 18:35:33.852010 140028400588544 deprecation.py:323] From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dense instead.\u001b[0m\n",
      "\u001b[34mW0219 18:35:34.172683 140028400588544 deprecation.py:323] From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[34mW0219 18:35:34.257917 140028400588544 deprecation_wrapper.py:119] From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0219 18:35:34.271479 140028400588544 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[34mW0219 18:35:34.282935 140028400588544 deprecation_wrapper.py:119] From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0219 18:35:34.283092 140028400588544 deprecation_wrapper.py:119] From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2020-02-19 18:35:34.997294: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[34mW0219 18:35:35.425674 140028400588544 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35mW0219 18:35:36.999541 140369995765504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.051827 140369995765504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.053334 140369995765504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.064159 140369995765504 deprecation.py:323] From mnist.py:46: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse `tf.keras.layers.Conv2D` instead.\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.066684 140369995765504 deprecation.py:506] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mCall initializer instance with the dtype argument instead of passing it to the constructor\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.306031 140369995765504 deprecation.py:323] From mnist.py:52: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.MaxPooling2D instead.\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.465818 140369995765504 deprecation.py:323] From mnist.py:81: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dense instead.\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.793208 140369995765504 deprecation.py:323] From mnist.py:85: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse keras.layers.dropout instead.\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.875622 140369995765504 deprecation_wrapper.py:119] From mnist.py:103: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.889247 140369995765504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mUse tf.where in 2.0, which has the same broadcast rule as np.where\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.900699 140369995765504 deprecation_wrapper.py:119] From mnist.py:107: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\u001b[0m\n",
      "\u001b[35mW0219 18:35:37.900868 140369995765504 deprecation_wrapper.py:119] From mnist.py:110: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\u001b[0m\n",
      "\u001b[35m2020-02-19 18:35:38.381980: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\u001b[0m\n",
      "\u001b[35mW0219 18:35:38.710287 140369995765504 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[35mInstructions for updating:\u001b[0m\n",
      "\u001b[35mTo construct input pipelines, use the `tf.data` module.\u001b[0m\n",
      "\u001b[35m2020-02-19 18:40:23.871320: W tensorflow/core/distributed_runtime/rpc/grpc_worker_service.cc:510] RecvTensor cancelled for 2979056902990595\u001b[0m\n",
      "\u001b[34mW0219 18:44:28.314921 140028400588544 deprecation_wrapper.py:119] From mnist.py:115: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0219 18:44:28.477760 140028400588544 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1282: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse standard file APIs to check for files with this prefix.\u001b[0m\n",
      "\u001b[34mW0219 18:44:29.875707 140028400588544 deprecation.py:323] From mnist.py:184: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function has been renamed, use `export_saved_model` instead.\u001b[0m\n",
      "\u001b[34mW0219 18:44:30.007561 140028400588544 deprecation_wrapper.py:119] From mnist.py:145: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mW0219 18:44:30.094324 140028400588544 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[35mW0219 18:45:44.277686 139747622438656 training.py:181] No model artifact is saved under path /opt/ml/model. Your training job will not save any model files to S3.\u001b[0m\n",
      "\u001b[35mFor details of how to construct your training script see:\u001b[0m\n",
      "\u001b[35mhttps://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/tensorflow#adapting-your-local-tensorflow-script\u001b[0m\n",
      "\n",
      "2020-02-19 18:45:55 Uploading - Uploading generated training model\n",
      "2020-02-19 18:45:55 Completed - Training job completed\n",
      "Training seconds: 1374\n",
      "Billable seconds: 1374\n"
     ]
    }
   ],
   "source": [
    "mnist_estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy the trained model to an endpoint\n",
    "\n",
    "The `deploy()` method creates a SageMaker model, which is then deployed to an endpoint to serve prediction requests in real time. We will use the TensorFlow Serving container for the endpoint, because we trained with script mode. This serving container runs an implementation of a web server that is compatible with SageMaker hosting protocol. The [Using your own inference code]() document explains how SageMaker runs inference containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------!"
     ]
    }
   ],
   "source": [
    "predictor = mnist_estimator.deploy(initial_instance_count=1, instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this predictor to classify hand-written digits. Drawing into the image box loads the pixel data into a 'data' variable in this notebook, which we can then pass to the mxnet predictor.\n",
    "\n",
    "The formats of the input and the output data correspond directly to the request and response formats of the Predict method in the TensorFlow Serving REST API. SageMaker's TensforFlow Serving endpoints can also accept additional input formats that are not part of the TensorFlow REST API, including the simplified JSON format, line-delimited JSON objects (\"jsons\" or \"jsonlines\"), and CSV data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/Javascript\">\n",
       "    var pixels = [];\n",
       "    for (var i = 0; i < 28*28; i++) pixels[i] = 0;\n",
       "    var click = 0;\n",
       "\n",
       "    var canvas = document.querySelector(\"canvas\");\n",
       "    canvas.addEventListener(\"mousemove\", function(e){\n",
       "        if (e.buttons == 1) {\n",
       "            click = 1;\n",
       "            canvas.getContext(\"2d\").fillStyle = \"rgb(0,0,0)\";\n",
       "            canvas.getContext(\"2d\").fillRect(e.offsetX, e.offsetY, 8, 8);\n",
       "            x = Math.floor(e.offsetY * 0.2);\n",
       "            y = Math.floor(e.offsetX * 0.2) + 1;\n",
       "            for (var dy = 0; dy < 2; dy++){\n",
       "                for (var dx = 0; dx < 2; dx++){\n",
       "                    if ((x + dx < 28) && (y + dy < 28)){\n",
       "                        pixels[(y+dy)+(x+dx)*28] = 1;\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "        } else {\n",
       "            if (click == 1) set_value();\n",
       "            click = 0;\n",
       "        }\n",
       "    });\n",
       "    function clear_value(){\n",
       "        canvas.getContext(\"2d\").fillStyle = \"rgb(255,255,255)\";\n",
       "        canvas.getContext(\"2d\").fillRect(0, 0, 140, 140);\n",
       "        for (var i = 0; i < 28*28; i++) pixels[i] = 0;\n",
       "    }\n",
       "    \n",
       "    function set_value(){\n",
       "        var result = \"[[\"\n",
       "        for (var i = 0; i < 28; i++) {\n",
       "            result += \"[\"\n",
       "            for (var j = 0; j < 28; j++) {\n",
       "                result += pixels [i * 28 + j]\n",
       "                if (j < 27) {\n",
       "                    result += \", \"\n",
       "                }\n",
       "            }\n",
       "            result += \"]\"\n",
       "            if (i < 27) {\n",
       "                result += \", \"\n",
       "            }\n",
       "        }\n",
       "        result += \"]]\"\n",
       "        var kernel = IPython.notebook.kernel;\n",
       "        kernel.execute(\"data = \" + result)\n",
       "    }\n",
       "</script>\n",
       "<table>\n",
       "<td style=\"border-style: none;\">\n",
       "<div style=\"border: solid 2px #666; width: 143px; height: 144px;\">\n",
       "<canvas width=\"140\" height=\"140\"></canvas>\n",
       "</div></td>\n",
       "<td style=\"border-style: none;\">\n",
       "<button onclick=\"clear_value()\">Clear</button>\n",
       "</td>\n",
       "</table>\n",
       "\n",
       "<!-- This work has been modified from the original and is licensed under the Apache 2.0 License. -->\n",
       "\n",
       "<!--\n",
       "                                     Apache License\n",
       "                           Version 2.0, January 2004\n",
       "                        http://www.apache.org/licenses/\n",
       "\n",
       "   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n",
       "\n",
       "   1. Definitions.\n",
       "\n",
       "      \"License\" shall mean the terms and conditions for use, reproduction,\n",
       "      and distribution as defined by Sections 1 through 9 of this document.\n",
       "\n",
       "      \"Licensor\" shall mean the copyright owner or entity authorized by\n",
       "      the copyright owner that is granting the License.\n",
       "\n",
       "      \"Legal Entity\" shall mean the union of the acting entity and all\n",
       "      other entities that control, are controlled by, or are under common\n",
       "      control with that entity. For the purposes of this definition,\n",
       "      \"control\" means (i) the power, direct or indirect, to cause the\n",
       "      direction or management of such entity, whether by contract or\n",
       "      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n",
       "      outstanding shares, or (iii) beneficial ownership of such entity.\n",
       "\n",
       "      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n",
       "      exercising permissions granted by this License.\n",
       "\n",
       "      \"Source\" form shall mean the preferred form for making modifications,\n",
       "      including but not limited to software source code, documentation\n",
       "      source, and configuration files.\n",
       "\n",
       "      \"Object\" form shall mean any form resulting from mechanical\n",
       "      transformation or translation of a Source form, including but\n",
       "      not limited to compiled object code, generated documentation,\n",
       "      and conversions to other media types.\n",
       "\n",
       "      \"Work\" shall mean the work of authorship, whether in Source or\n",
       "      Object form, made available under the License, as indicated by a\n",
       "      copyright notice that is included in or attached to the work\n",
       "      (an example is provided in the Appendix below).\n",
       "\n",
       "      \"Derivative Works\" shall mean any work, whether in Source or Object\n",
       "      form, that is based on (or derived from) the Work and for which the\n",
       "      editorial revisions, annotations, elaborations, or other modifications\n",
       "      represent, as a whole, an original work of authorship. For the purposes\n",
       "      of this License, Derivative Works shall not include works that remain\n",
       "      separable from, or merely link (or bind by name) to the interfaces of,\n",
       "      the Work and Derivative Works thereof.\n",
       "\n",
       "      \"Contribution\" shall mean any work of authorship, including\n",
       "      the original version of the Work and any modifications or additions\n",
       "      to that Work or Derivative Works thereof, that is intentionally\n",
       "      submitted to Licensor for inclusion in the Work by the copyright owner\n",
       "      or by an individual or Legal Entity authorized to submit on behalf of\n",
       "      the copyright owner. For the purposes of this definition, \"submitted\"\n",
       "      means any form of electronic, verbal, or written communication sent\n",
       "      to the Licensor or its representatives, including but not limited to\n",
       "      communication on electronic mailing lists, source code control systems,\n",
       "      and issue tracking systems that are managed by, or on behalf of, the\n",
       "      Licensor for the purpose of discussing and improving the Work, but\n",
       "      excluding communication that is conspicuously marked or otherwise\n",
       "      designated in writing by the copyright owner as \"Not a Contribution.\"\n",
       "\n",
       "      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n",
       "      on behalf of whom a Contribution has been received by Licensor and\n",
       "      subsequently incorporated within the Work.\n",
       "\n",
       "   2. Grant of Copyright License. Subject to the terms and conditions of\n",
       "      this License, each Contributor hereby grants to You a perpetual,\n",
       "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
       "      copyright license to reproduce, prepare Derivative Works of,\n",
       "      publicly display, publicly perform, sublicense, and distribute the\n",
       "      Work and such Derivative Works in Source or Object form.\n",
       "\n",
       "   3. Grant of Patent License. Subject to the terms and conditions of\n",
       "      this License, each Contributor hereby grants to You a perpetual,\n",
       "      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n",
       "      (except as stated in this section) patent license to make, have made,\n",
       "      use, offer to sell, sell, import, and otherwise transfer the Work,\n",
       "      where such license applies only to those patent claims licensable\n",
       "      by such Contributor that are necessarily infringed by their\n",
       "      Contribution(s) alone or by combination of their Contribution(s)\n",
       "      with the Work to which such Contribution(s) was submitted. If You\n",
       "      institute patent litigation against any entity (including a\n",
       "      cross-claim or counterclaim in a lawsuit) alleging that the Work\n",
       "      or a Contribution incorporated within the Work constitutes direct\n",
       "      or contributory patent infringement, then any patent licenses\n",
       "      granted to You under this License for that Work shall terminate\n",
       "      as of the date such litigation is filed.\n",
       "\n",
       "   4. Redistribution. You may reproduce and distribute copies of the\n",
       "      Work or Derivative Works thereof in any medium, with or without\n",
       "      modifications, and in Source or Object form, provided that You\n",
       "      meet the following conditions:\n",
       "\n",
       "      (a) You must give any other recipients of the Work or\n",
       "          Derivative Works a copy of this License; and\n",
       "\n",
       "      (b) You must cause any modified files to carry prominent notices\n",
       "          stating that You changed the files; and\n",
       "\n",
       "      (c) You must retain, in the Source form of any Derivative Works\n",
       "          that You distribute, all copyright, patent, trademark, and\n",
       "          attribution notices from the Source form of the Work,\n",
       "          excluding those notices that do not pertain to any part of\n",
       "          the Derivative Works; and\n",
       "\n",
       "      (d) If the Work includes a \"NOTICE\" text file as part of its\n",
       "          distribution, then any Derivative Works that You distribute must\n",
       "          include a readable copy of the attribution notices contained\n",
       "          within such NOTICE file, excluding those notices that do not\n",
       "          pertain to any part of the Derivative Works, in at least one\n",
       "          of the following places: within a NOTICE text file distributed\n",
       "          as part of the Derivative Works; within the Source form or\n",
       "          documentation, if provided along with the Derivative Works; or,\n",
       "          within a display generated by the Derivative Works, if and\n",
       "          wherever such third-party notices normally appear. The contents\n",
       "          of the NOTICE file are for informational purposes only and\n",
       "          do not modify the License. You may add Your own attribution\n",
       "          notices within Derivative Works that You distribute, alongside\n",
       "          or as an addendum to the NOTICE text from the Work, provided\n",
       "          that such additional attribution notices cannot be construed\n",
       "          as modifying the License.\n",
       "\n",
       "      You may add Your own copyright statement to Your modifications and\n",
       "      may provide additional or different license terms and conditions\n",
       "      for use, reproduction, or distribution of Your modifications, or\n",
       "      for any such Derivative Works as a whole, provided Your use,\n",
       "      reproduction, and distribution of the Work otherwise complies with\n",
       "      the conditions stated in this License.\n",
       "\n",
       "   5. Submission of Contributions. Unless You explicitly state otherwise,\n",
       "      any Contribution intentionally submitted for inclusion in the Work\n",
       "      by You to the Licensor shall be under the terms and conditions of\n",
       "      this License, without any additional terms or conditions.\n",
       "      Notwithstanding the above, nothing herein shall supersede or modify\n",
       "      the terms of any separate license agreement you may have executed\n",
       "      with Licensor regarding such Contributions.\n",
       "\n",
       "   6. Trademarks. This License does not grant permission to use the trade\n",
       "      names, trademarks, service marks, or product names of the Licensor,\n",
       "      except as required for reasonable and customary use in describing the\n",
       "      origin of the Work and reproducing the content of the NOTICE file.\n",
       "\n",
       "   7. Disclaimer of Warranty. Unless required by applicable law or\n",
       "      agreed to in writing, Licensor provides the Work (and each\n",
       "      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n",
       "      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
       "      implied, including, without limitation, any warranties or conditions\n",
       "      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n",
       "      PARTICULAR PURPOSE. You are solely responsible for determining the\n",
       "      appropriateness of using or redistributing the Work and assume any\n",
       "      risks associated with Your exercise of permissions under this License.\n",
       "\n",
       "   8. Limitation of Liability. In no event and under no legal theory,\n",
       "      whether in tort (including negligence), contract, or otherwise,\n",
       "      unless required by applicable law (such as deliberate and grossly\n",
       "      negligent acts) or agreed to in writing, shall any Contributor be\n",
       "      liable to You for damages, including any direct, indirect, special,\n",
       "      incidental, or consequential damages of any character arising as a\n",
       "      result of this License or out of the use or inability to use the\n",
       "      Work (including but not limited to damages for loss of goodwill,\n",
       "      work stoppage, computer failure or malfunction, or any and all\n",
       "      other commercial damages or losses), even if such Contributor\n",
       "      has been advised of the possibility of such damages.\n",
       "\n",
       "   9. Accepting Warranty or Additional Liability. While redistributing\n",
       "      the Work or Derivative Works thereof, You may choose to offer,\n",
       "      and charge a fee for, acceptance of support, warranty, indemnity,\n",
       "      or other liability obligations and/or rights consistent with this\n",
       "      License. However, in accepting such obligations, You may act only\n",
       "      on Your own behalf and on Your sole responsibility, not on behalf\n",
       "      of any other Contributor, and only if You agree to indemnify,\n",
       "      defend, and hold each Contributor harmless for any liability\n",
       "      incurred by, or claims asserted against, such Contributor by reason\n",
       "      of your accepting any such warranty or additional liability.\n",
       "\n",
       "   END OF TERMS AND CONDITIONS\n",
       "\n",
       "   APPENDIX: How to apply the Apache License to your work.\n",
       "\n",
       "      To apply the Apache License to your work, attach the following\n",
       "      boilerplate notice, with the fields enclosed by brackets \"{}\"\n",
       "      replaced with your own identifying information. (Don't include\n",
       "      the brackets!)  The text should be enclosed in the appropriate\n",
       "      comment syntax for the file format. We also recommend that a\n",
       "      file or class name and description of purpose be included on the\n",
       "      same \"printed page\" as the copyright notice for easier\n",
       "      identification within third-party archives.\n",
       "\n",
       "   Copyright {yyyy} {name of copyright owner}\n",
       "\n",
       "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "   you may not use this file except in compliance with the License.\n",
       "   You may obtain a copy of the License at\n",
       "\n",
       "       http://www.apache.org/licenses/LICENSE-2.0\n",
       "\n",
       "   Unless required by applicable law or agreed to in writing, software\n",
       "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "   See the License for the specific language governing permissions and\n",
       "   limitations under the License.\n",
       "-->\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open(\"input.html\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "response = predictor.predict(data)\n",
    "print(response['predictions'][0]['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoke the endpoint\n",
    "\n",
    "Let's download the training data and use that as input for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-sample-data-us-east-1/tensorflow/mnist/train_data.npy to ./train_data.npy\n",
      "download: s3://sagemaker-sample-data-us-east-1/tensorflow/mnist/train_labels.npy to ./train_labels.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "!aws --region {region} s3 cp s3://sagemaker-sample-data-{region}/tensorflow/mnist/train_data.npy train_data.npy\n",
    "!aws --region {region} s3 cp s3://sagemaker-sample-data-{region}/tensorflow/mnist/train_labels.npy train_labels.npy\n",
    "\n",
    "train_data = np.load('train_data.npy')\n",
    "train_labels = np.load('train_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formats of the input and the output data correspond directly to the request and response formats of the `Predict` method in the [TensorFlow Serving REST API](https://www.tensorflow.org/serving/api_rest). SageMaker's TensforFlow Serving endpoints can also accept additional input formats that are not part of the TensorFlow REST API, including the simplified JSON format, line-delimited JSON objects (\"jsons\" or \"jsonlines\"), and CSV data.\n",
    "\n",
    "In this example we are using a `numpy` array as input, which will be serialized into the simplified JSON format. In addtion, TensorFlow serving can also process multiple items at once as you can see in the following code. You can find the complete documentation on how to make predictions against a TensorFlow serving SageMaker endpoint [here](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/deploying_tensorflow_serving.rst#making-predictions-against-a-sagemaker-endpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is 8, label is 7, matched: False\n",
      "prediction is 1, label is 3, matched: False\n",
      "prediction is 1, label is 4, matched: False\n",
      "prediction is 1, label is 6, matched: False\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 1, label is 8, matched: False\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 1, label is 0, matched: False\n",
      "prediction is 3, label is 9, matched: False\n",
      "prediction is 1, label is 8, matched: False\n",
      "prediction is 8, label is 0, matched: False\n",
      "prediction is 3, label is 3, matched: True\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 1, label is 2, matched: False\n",
      "prediction is 0, label is 7, matched: False\n",
      "prediction is 1, label is 0, matched: False\n",
      "prediction is 1, label is 2, matched: False\n",
      "prediction is 8, label is 9, matched: False\n",
      "prediction is 3, label is 6, matched: False\n",
      "prediction is 3, label is 0, matched: False\n",
      "prediction is 1, label is 1, matched: True\n",
      "prediction is 1, label is 6, matched: False\n",
      "prediction is 0, label is 7, matched: False\n",
      "prediction is 3, label is 1, matched: False\n",
      "prediction is 3, label is 9, matched: False\n",
      "prediction is 1, label is 7, matched: False\n",
      "prediction is 8, label is 6, matched: False\n",
      "prediction is 1, label is 5, matched: False\n",
      "prediction is 1, label is 5, matched: False\n",
      "prediction is 3, label is 8, matched: False\n",
      "prediction is 1, label is 8, matched: False\n",
      "prediction is 1, label is 3, matched: False\n",
      "prediction is 3, label is 4, matched: False\n",
      "prediction is 3, label is 4, matched: False\n",
      "prediction is 1, label is 8, matched: False\n",
      "prediction is 1, label is 7, matched: False\n",
      "prediction is 1, label is 3, matched: False\n",
      "prediction is 3, label is 6, matched: False\n",
      "prediction is 3, label is 4, matched: False\n",
      "prediction is 1, label is 6, matched: False\n",
      "prediction is 3, label is 6, matched: False\n",
      "prediction is 1, label is 3, matched: False\n",
      "prediction is 8, label is 8, matched: True\n",
      "prediction is 3, label is 8, matched: False\n",
      "prediction is 1, label is 9, matched: False\n",
      "prediction is 3, label is 9, matched: False\n",
      "prediction is 8, label is 4, matched: False\n",
      "prediction is 3, label is 4, matched: False\n",
      "prediction is 1, label is 0, matched: False\n",
      "prediction is 1, label is 7, matched: False\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(train_data[:50])\n",
    "for i in range(0, 50):\n",
    "    prediction = predictions['predictions'][i]['classes']\n",
    "    label = train_labels[i]\n",
    "    print('prediction is {}, label is {}, matched: {}'.format(prediction, label, prediction == label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete the endpoint\n",
    "\n",
    "Let's delete the endpoint we just created to prevent incurring any extra costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
